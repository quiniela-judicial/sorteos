{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parser(html):\n",
    "    \"\"\"\n",
    "    Parse the html to lines.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    html: str\n",
    "     Html text to parse\n",
    "     \n",
    "    Return\n",
    "    ------\n",
    "    lines: like-list\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.find_all('div', {'class':'result'})\n",
    "    \n",
    "    # No se por que, pero hay algunos elementos que\n",
    "    # nos son visibles y no me interesan\n",
    "    if len(results) > 6:\n",
    "        results = results[:6]\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    lines = []\n",
    "    for result in results:\n",
    "        ul_general = result.find('ul')\n",
    "\n",
    "        data = {}\n",
    "        for cnt_li, li_general in enumerate(ul_general.find_all('li', recursive=False)):\n",
    "            # Text\n",
    "            text = ' '.join(li_general.text.split())\n",
    "            \n",
    "            # Find the key\n",
    "            key = li_general.find('span').text\n",
    "            key = ' '.join(key.split()).replace(':', '')\n",
    "            if key not in valid_keys:\n",
    "                continue\n",
    "\n",
    "            # Remove the key form the text\n",
    "            text = text.replace(key, '', 1)\n",
    "            # Remove \"\n",
    "            text = text.replace('\"', \"'\")\n",
    "            # If the text start with ':', remove it\n",
    "            if text.startswith(':'):\n",
    "                text = text[1:]\n",
    "            # If the text end with ',', remove it\n",
    "            if text.endswith(','):\n",
    "                text = text[:-1]\n",
    "            # Remove 'mas info' and similar words\n",
    "            for word in replaces_words:\n",
    "                if word in text:\n",
    "                    text = text.replace(word, '')\n",
    "            # Remove extra white spaces\n",
    "            text = ' '.join(text.split())\n",
    "\n",
    "            # Caratula sub clase\n",
    "            # ==================\n",
    "            involucrados = []\n",
    "            involucrados_tipo = []\n",
    "            letrados = []\n",
    "            if key == 'Carátula':\n",
    "                div = li_general.find_all('div', {'class': 'resalta'})\n",
    "                caratula_type = [''.join(s.text.replace(':', '').split()) \n",
    "                                 for s in div]\n",
    "                caratula_type = [s for s in caratula_type \n",
    "                                 if s in sub_caratula]\n",
    "                \n",
    "                uls_sub = li_general.find_all('ul')\n",
    "                for cnt, ul_sub in enumerate(uls_sub):\n",
    "\n",
    "                    for li_sub in ul_sub.find_all('li'):\n",
    "                        text_sub = ' '.join(li_sub.text.split())\n",
    "                        \n",
    "                        # if text_sub endswith ' CERRAR', remove it\n",
    "                        if text_sub.endswith(' CERRAR'):\n",
    "                            text_sub = text_sub[:-7]\n",
    "                        \n",
    "                        if 'VER LETRADOS Letrados' in text_sub:\n",
    "                            persona, letrado = text_sub.split('VER LETRADOS Letrados')\n",
    "                        else:\n",
    "                            persona = text_sub\n",
    "                            letrado = ''\n",
    "                        \n",
    "                        letrado = [' '.join(name.text.split()) for name in \n",
    "                                   li_sub.find_all('div', {'class': 'item'})]\n",
    "                        \n",
    "                        letrado = [' '.join(let.split()) for let in letrado]\n",
    "                        letrado = [let.replace(',', ' ') for let in letrado]\n",
    "                        letrado = [let.replace('.', '') for let in letrado]\n",
    "                        letrado = [unidecode(let).upper() for let in letrado]\n",
    "                        \n",
    "                        involucrados.append(persona)\n",
    "                        involucrados_tipo.append(caratula_type[cnt])\n",
    "                        letrados.append(letrado)\n",
    "\n",
    "                # Remove white spaces, dot and accent in the text\n",
    "                # to make the names equals\n",
    "                involucrados = [' '.join(invo.split()) for invo in involucrados]\n",
    "                involucrados = [invo.replace('.', '') for invo in involucrados]\n",
    "                involucrados = [invo.replace(',', '') for invo in involucrados]\n",
    "                involucrados = [unidecode(invo).upper() for invo in involucrados]\n",
    "                \n",
    "                # Append to data\n",
    "                data['involucrados'] = involucrados\n",
    "                data['involucrados_tipo'] = involucrados_tipo\n",
    "                data['letrados'] = letrados\n",
    "\n",
    "            # Resolución/es sub clase\n",
    "            # =======================\n",
    "            resoluciones_sala = []\n",
    "            resoluciones_link = []\n",
    "            if key == 'Resolución/es':\n",
    "                for link in li_general.find_all('a'):\n",
    "                    if link.text.startswith('Ver'):\n",
    "                        continue\n",
    "                    else:\n",
    "                        resoluciones_sala.append(link.text)\n",
    "                        resoluciones_link.append(link.attrs['href'])\n",
    "            \n",
    "                data['resoluciones_sala'] = resoluciones_sala\n",
    "                data['resoluciones_link'] = resoluciones_link\n",
    "\n",
    "            # Radicacion sub clase\n",
    "            # ====================\n",
    "            radicacion_fecha = []\n",
    "            radicacion_sala = []\n",
    "            radicacion_fiscal = []\n",
    "            radicacion_fiscalia = []\n",
    "            if key == 'Radicación del expediente':\n",
    "                for items in li_general.find_all('div', {'class': 'item-especial-largo'}):\n",
    "                    fecha = items.find('div', {'class': 't1a'}).text\n",
    "                    sala = items.find('div', {'class': 't2a'}).text\n",
    "                    fiscal = items.find('div', {'class': 't3a'})\n",
    "                    fiscalia = items.find('div', {'class': 't2a'})\n",
    "                    \n",
    "                    # Remove white space\n",
    "                    fecha = ' '.join(fecha.split())\n",
    "                    \n",
    "                    # Algunos fiscales o fiscalias no estan\n",
    "                    if fiscal:\n",
    "                        fiscal = fiscal.text.replace('Fiscal: ', '')\n",
    "                        radicacion_fiscal.append(fiscal)\n",
    "                    else:\n",
    "                        radicacion_fiscal.append('')\n",
    "                    if fiscalia:\n",
    "                        radicacion_fiscalia.append(fiscalia.text)\n",
    "                    else:\n",
    "                        radicacion_fiscalia.append('')\n",
    "                    \n",
    "                    radicacion_fecha.append(fecha)\n",
    "                    radicacion_sala.append(sala)\n",
    "                        \n",
    "                data['radicacion_fecha'] = radicacion_fecha\n",
    "                data['radicacion_sala'] = radicacion_sala\n",
    "                data['radicacion_fiscal'] = radicacion_fiscal\n",
    "                data['radicacion_fiscalia'] = radicacion_fiscalia\n",
    "                \n",
    "            if key == 'Carátula':\n",
    "                text, rest = text.split(' VER INTERVINIENTES')\n",
    "\n",
    "            data[key] = text\n",
    "        \n",
    "        # Some data miss some keys\n",
    "        for key in valid_keys:\n",
    "            if key not in data.keys():\n",
    "                data[key] = ''\n",
    "                \n",
    "        for key in valid_keys_2:\n",
    "            if key not in data.keys():\n",
    "                data[key] = ''\n",
    "        \n",
    "        #\n",
    "        lines.append(data)\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base url to make the gets\n",
    "url = \"http://www.cij.gov.ar/causas-de-corrupcion.html\"\n",
    "\n",
    "# Set the header and share the cookies in all the requests\n",
    "headers = {\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate',\n",
    "    'User-Agent': ('Mozilla/5.0 (X11; Linux x86_64; rv:45.0)'\n",
    "                   ' Gecko/20100101 Firefox/45.0'),\n",
    "}\n",
    "session = requests.Session()\n",
    "session.headers = headers\n",
    "\n",
    "# Form to make the posts\n",
    "form = {\"accion\": \"buscar\",\n",
    "        \"origenPaginado\": \"S1\",\n",
    "        \"paginaS1\": \"\",\n",
    "        \"paginaS2\": \"\",\n",
    "        \"paginaP\": \"\",\n",
    "        \"prefijo\": \"\",\n",
    "        \"expediente\": \"\",\n",
    "        \"anio\": \"\",\n",
    "        \"fecha_resolucion_desde\": \"\",\n",
    "        \"fecha_resolucion_desde_aux\": \"\",\n",
    "        \"fecha_resolucion_hasta\": \"\",\n",
    "        \"fecha_resolucion_hasta_aux\": \"\",\n",
    "        \"fecha_fallo_desde\": \"\",\n",
    "        \"fecha_fallo_desde_aux\": \"\",\n",
    "        \"fecha_fallo_hasta\": \"\",\n",
    "        \"fecha_fallo_hasta_aux\": \"\",\n",
    "        \"tribunal\": \"\",\n",
    "        \"fiscalia\": \"\",\n",
    "        \"fiscal\": \"\",\n",
    "        \"estado\": \"\",\n",
    "        \"nombre[]\": \"\",\n",
    "        \"letrado\": \"\",\n",
    "        \"orden\": \"actualizacion\"}\n",
    "\n",
    "# Search this keys\n",
    "valid_keys = ['Expediente', 'Carátula', 'Delitos', 'Radicación del expediente',\n",
    "              'Estado', 'Resolución/es', 'Última actualización']\n",
    "valid_keys_2 = ['resoluciones_sala', 'resoluciones_link', 'radicacion_fecha',\n",
    "                'radicacion_sala', 'radicacion_fiscal', 'radicacion_fiscalia',\n",
    "                'involucrados', 'involucrados_tipo', 'letrados']\n",
    "\n",
    "# Words to replace\n",
    "replaces_words = ['VER MÁS', 'VER MENOS', 'CERRAR']\n",
    "# Sub categories\n",
    "sub_caratula = ['DENUNCIADO', 'DENUNCIADOS', 'DENUNCIANTE', 'DENUNCIANTES', \n",
    "                'QUERELLANTE', 'QUERELLANTES', 'IMPUTADO', 'IMPUTADOS',\n",
    "                'PROCESADOS', 'PROCESADO', 'DEMANDADO', 'DEMANDADOS']\n",
    "\n",
    "# Keys per files\n",
    "causas = ['Expediente', 'Carátula', 'Delitos', 'Estado', 'Última actualización']\n",
    "resolucion = ['Expediente', 'Fecha resolucion', 'Sala', 'PDF link']\n",
    "radicacion = ['Expediente', 'Fecha radicacion', 'Sala', 'Fiscal', 'Fiscalia']\n",
    "implicados = ['Expediente', 'Nombre implicado', 'Tipo implicado', 'Letrado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to save the CSV\n",
    "base_dir = '../data/'\n",
    "\n",
    "# Create the output directory\n",
    "if not os.path.isdir(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "    os.mkdir(base_dir + 'PDFs')\n",
    "\n",
    "# Output file\n",
    "file_causas = open(base_dir + 'causas.csv', 'a')\n",
    "file_implicados = open(base_dir + 'implicados.csv', 'a')\n",
    "file_resolucion = open(base_dir + 'resolucion.csv', 'a')\n",
    "file_radicacion = open(base_dir + 'radicacion.csv', 'a')\n",
    "\n",
    "# Line format\n",
    "line_causas = '''{0},\"{1}\",\"{2}\",\"{3}\",\"{4}\"\\n'''\n",
    "line_implicados = '''{0},{1},{2},{3}\\n'''\n",
    "line_resolucion = '''{0},{1},{2},{3}\\n'''\n",
    "line_radicacion = '''{0},{1},{2},{3},{4}\\n'''\n",
    "\n",
    "# CSV head\n",
    "head_causas = ','.join(causas)\n",
    "head_implicados = ','.join(implicados)\n",
    "head_resolucion = ','.join(resolucion)\n",
    "head_radicacion = ','.join(radicacion)\n",
    "\n",
    "# Write head\n",
    "if os.stat(base_dir + 'causas.csv').st_size == 0:\n",
    "    file_causas.write(head_causas + '\\n')\n",
    "    file_implicados.write(head_implicados + '\\n')\n",
    "    file_resolucion.write(head_resolucion + '\\n')\n",
    "    file_radicacion.write(head_radicacion + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando el scraping ...\n",
      "Descargando pagina: 2. Casusas bajadas: 12"
     ]
    }
   ],
   "source": [
    "request_count = 0\n",
    "causas_count = 0\n",
    "\n",
    "print(\"Comenzando el scraping ...\")\n",
    "\n",
    "while True:\n",
    "    # Progress text\n",
    "    text_progress = \"\\rDescargando pagina: {0}. Casusas bajadas: {1}\"\n",
    "    print(text_progress.format(request_count, causas_count), end='')\n",
    "\n",
    "    # Make the get\n",
    "    form[\"paginaS1\"] = str(request_count)\n",
    "    response = session.post(url, data=form)\n",
    "    lines = parser(response.text)\n",
    "\n",
    "    if not lines:\n",
    "        print(\"\\nScraping terminado\")\n",
    "        break\n",
    "\n",
    "    # Save to CSVs\n",
    "    for line in lines:\n",
    "        # Causas file\n",
    "        partial = [line[key] for key in causas]\n",
    "        file_causas.write(line_causas.format(*partial))\n",
    "\n",
    "        # Implicados file\n",
    "        for invo, invo_tipo, letrado in zip(line['involucrados'], \n",
    "                                            line['involucrados_tipo'], \n",
    "                                            line['letrados']):\n",
    "            for let in letrado:\n",
    "                file_implicados.write(line_implicados.format(line['Expediente'], \n",
    "                                                             invo, invo_tipo, let))\n",
    "            \n",
    "        # Resoluciones file\n",
    "        for resolucion, link in zip(line['resoluciones_sala'], \n",
    "                                    line['resoluciones_link']):\n",
    "            date, room = resolucion.split(':', 1)\n",
    "            link = 'http://www.cij.gov.ar' + link\n",
    "            file_resolucion.write(line_resolucion.format(line['Expediente'], \n",
    "                                                         date, room, link))\n",
    "\n",
    "        # Radicacion file\n",
    "        for fecha, sala, fiscal, fiscalia in zip(line['radicacion_fecha'],\n",
    "                                                 line['radicacion_sala'],\n",
    "                                                 line['radicacion_fiscal'],\n",
    "                                                 line['radicacion_fiscalia']):\n",
    "            file_radicacion.write(line_radicacion.format(line['Expediente'],\n",
    "                                                         fecha, sala, fiscal, \n",
    "                                                         fiscalia))\n",
    "            \n",
    "    request_count += 1\n",
    "    causas_count += len(lines)\n",
    "\n",
    "file_causas.close()\n",
    "file_implicados.close()\n",
    "file_radicacion.close()\n",
    "file_resolucion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEliminando datos duplicados: ...\", end='')\n",
    "\n",
    "# Eliminando filas duplicadas en los csv\n",
    "file_names = ['causas.csv', 'implicados.csv', 'resolucion.csv', 'radicacion.csv']\n",
    "for name in file_names:\n",
    "    df = pd.read_csv(base_dir + name)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.to_csv(base_dir + name, index=False)\n",
    "    \n",
    "print(\"\\rEliminando datos duplicados: Terminado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
